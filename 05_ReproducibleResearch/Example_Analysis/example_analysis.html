<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Decreases in Fine Particle Air Pollution Between 1999 and 2012</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<h1>Decreases in Fine Particle Air Pollution Between 1999 and 2012</h1>

<h2>Synopsis</h2>

<p>In this report we aim to describe the changes in fine particle (PM<sub>2.5</sub>) outdoor air pollution in the United States between the years 1999 and 2012. Our overall hypothesis is that out door PM<sub>2.5</sub> has decreased on average across the U.S. due to nationwide regulatory requirements arising from the Clean Air Act. To investigate this hypothesis, we obtained PM<sub>2.5</sub> data from the U.S. Environmental Protection Agency which is collected from monitors sited across the U.S. We specifically obtained data for the years 1999 and 2012 (the most recent complete year available). From these data, we found that, on average across the U.S., levels of PM<sub>2.5</sub> have decreased between 1999 and 2012. At one individual monitor, we found that levels have decreased and that the variability of PM<sub>2.5</sub> has decreased. Most individual states also experienced decreases in PM<sub>2.5</sub>, although some states saw increases.</p>

<h2>Loading and Processing the Raw Data</h2>

<p>From the <a href="http://www.epa.gov/ttn/airs/airsaqs/detaildata/downloadaqsdata.htm">EPA Air Quality System</a> we obtained data on fine particulate matter air pollution (PM<sub>2.5</sub>) that is monitored across the U.S. as part of the nationwide PM monitoring network. We obtained the files for the years <a href="http://www.epa.gov/ttn/airs/airsaqs/detaildata/501files/Rd_501_88101_1999.Zip">1999</a> and <a href="http://www.epa.gov/ttn/airs/airsaqs/detaildata/501files/RD_501_88101_2012%5B1%5D.zip">2012</a>.</p>

<h3>Reading in the 1999 data</h3>

<p>We first read in the 1999 data from the raw text file included in the zip archive. The data is a delimited file were fields are delimited with the <code>|</code> character adn missing values are coded as blank fields. We skip some commented lines in the beginning of the file and initially we do not read the header data.</p>

<pre><code class="r">pm0 &lt;- read.table(&quot;pm25_data/RD_501_88101_1999-0.txt&quot;, comment.char = &quot;#&quot;, 
                  header = FALSE, sep = &quot;|&quot;, na.strings = &quot;&quot;)
</code></pre>

<p>After reading in the 1999 we check the first few rows (there are 117,421) rows in this dataset. </p>

<pre><code class="r">dim(pm0)
</code></pre>

<pre><code>## [1] 117421     28
</code></pre>

<pre><code class="r">head(pm0[, 1:13])
</code></pre>

<pre><code>##   V1 V2 V3 V4 V5    V6 V7 V8  V9 V10      V11   V12    V13
## 1 RD  I  1 27  1 88101  1  7 105 120 19990103 00:00     NA
## 2 RD  I  1 27  1 88101  1  7 105 120 19990106 00:00     NA
## 3 RD  I  1 27  1 88101  1  7 105 120 19990109 00:00     NA
## 4 RD  I  1 27  1 88101  1  7 105 120 19990112 00:00  8.841
## 5 RD  I  1 27  1 88101  1  7 105 120 19990115 00:00 14.920
## 6 RD  I  1 27  1 88101  1  7 105 120 19990118 00:00  3.878
</code></pre>

<p>We then attach the column headers to the dataset and make sure that they are properly formated for R data frames.</p>

<pre><code class="r">cnames &lt;- readLines(&quot;pm25_data/RD_501_88101_1999-0.txt&quot;, 1)
cnames &lt;- strsplit(cnames, &quot;|&quot;, fixed = TRUE)
names(pm0) &lt;- make.names(cnames[[1]])  ## Ensure names are properly formatted
head(pm0[, 1:13])
</code></pre>

<pre><code>##   X..RD Action.Code State.Code County.Code Site.ID Parameter POC
## 1    RD           I          1          27       1     88101   1
## 2    RD           I          1          27       1     88101   1
## 3    RD           I          1          27       1     88101   1
## 4    RD           I          1          27       1     88101   1
## 5    RD           I          1          27       1     88101   1
## 6    RD           I          1          27       1     88101   1
##   Sample.Duration Unit Method     Date Start.Time Sample.Value
## 1               7  105    120 19990103      00:00           NA
## 2               7  105    120 19990106      00:00           NA
## 3               7  105    120 19990109      00:00           NA
## 4               7  105    120 19990112      00:00        8.841
## 5               7  105    120 19990115      00:00       14.920
## 6               7  105    120 19990118      00:00        3.878
</code></pre>

<p>The column we are interested in is the <code>Sample.Value</code> column which contains the PM<sub>2.5</sub> measurements. Here we extract that column and print a brief summary.</p>

<pre><code class="r">x0 &lt;- pm0$Sample.Value
summary(x0)
</code></pre>

<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##       0       7      12      14      18     157   13217
</code></pre>

<p>Missing values are a common problem with environmental data and so we check to se what proportion of the observations are missing (i.e. coded as <code>NA</code>).</p>

<pre><code class="r">mean(is.na(x0))  ## Are missing values important here?
</code></pre>

<pre><code>## [1] 0.1126
</code></pre>

<p>Because the proportion of missing values is relatively low (0.1126), we choose to ignore missing values for now.</p>

<h3>Reading in the 2012 data</h3>

<p>We then read in the 2012 data in the same manner in which we read the 1999 data (the data files are in the same format). </p>

<pre><code class="r">pm1 &lt;- read.table(&quot;pm25_data/RD_501_88101_2012-0.txt&quot;, comment.char = &quot;#&quot;, 
                  header = FALSE, sep = &quot;|&quot;, na.strings = &quot;&quot;, nrow = 1304290)
</code></pre>

<p>We also set the column names (they are the same ast the 1999 dataset) and extract the <code>Sample.Value</code> column from this dataset.</p>

<pre><code class="r">names(pm1) &lt;- make.names(cnames[[1]])
x1 &lt;- pm1$Sample.Value
</code></pre>

<h2>Results</h2>

<h3>Entire U.S. analysis</h3>

<p>In order to show aggregate changes in PM across the entire monitoring network, we can make boxplots of all monitor values in 1999 and 2012. Here, we take the log of the PM values to adjust for the skew in the data.</p>

<pre><code class="r">boxplot(log2(x0), log2(x1))
</code></pre>

<pre><code>## Warning: NaNs produced
## Warning: Outlier (-Inf) in boxplot 1 is not drawn
## Warning: Outlier (-Inf) in boxplot 2 is not drawn
</code></pre>

<p><img src="figure/boxplot_log_values.png" alt="plot of chunk boxplot log values"/> </p>

<pre><code class="r">summary(x0)
</code></pre>

<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##       0       7      12      14      18     157   13217
</code></pre>

<pre><code class="r">summary(x1)
</code></pre>

<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##     -10       4       8       9      12     909   73133
</code></pre>

<p>Interestingly, from the summary of <code>x1</code> it appears there are some negative values of PM, which in general should not occur. We can investigate that somewhat to see if there is anything we should worry about.</p>

<pre><code class="r">negative &lt;- x1 &lt; 0
mean(negative, na.rm = T)
</code></pre>

<pre><code>## [1] 0.0215
</code></pre>

<p>There is a relatively small proportion of values that are negative, which is perhaps reassuring. In order to investigate this a step further we can extract the date of each measurement from the original data frame. The idea here is that perhaps negative values occur more often in some parts of the year than other parts. However, the original data are formatted as character strings so we convert them to R&#39;s <code>Date</code> format for easier manipulation.</p>

<pre><code class="r">dates &lt;- pm1$Date
dates &lt;- as.Date(as.character(dates), &quot;%Y%m%d&quot;)
</code></pre>

<p>We can then extract the month from each of the dates with negative values and attempt to identify when negative values occur most often.</p>

<pre><code class="r">missing.months &lt;- month.name[as.POSIXlt(dates)$mon + 1]
tab &lt;- table(factor(missing.months, levels = month.name))
round(100 * tab/sum(tab))
</code></pre>

<pre><code>## 
##   January  February     March     April       May      June      July 
##        15        13        15        13        14        13         8 
##    August September   October  November  December 
##         6         3         0         0         0
</code></pre>

<p>From the table above it appears that bulk of the negative values occur in the first six months of the year (January&ndash;June). However, beyond that simple observation, it is not clear why the negative values occur. That said, given the relatively low proportion of negative values, we will ignore them for now.</p>

<h3>Changes in PM levels at an individual monitor</h3>

<p>So far we have examined the change in PM levels on average across the country. One issue with the previous analysis is that the monitoring network could have changed in the time period between 1999 and 2012. So if for some reason in 2012 there are more monitors concentrated in cleaner parts of the country than there were in 1999, it might appear the PM levels decreased when in fact they didn&#39;t. In this section we will focus on a single monitor in New York State to see if PM levels <em>at that monitor</em> decreased from 1999 to 2012. </p>

<p>Our first task is to identify a monitor in New York State that has data in 1999 and 2012 (not all monitors operated during both time periods). First we subset the data frames to only include data from New York (<code>State.Code == 36</code>) and only include the <code>County.Code</code> and the <code>Site.ID</code> (i.e. monitor number) variables.</p>

<pre><code class="r">site0 &lt;- unique(subset(pm0, State.Code == 36, c(County.Code, Site.ID)))
site1 &lt;- unique(subset(pm1, State.Code == 36, c(County.Code, Site.ID)))
</code></pre>

<p>Then we create a new variable that combines the county code and the site ID into a single string.</p>

<pre><code class="r">site0 &lt;- paste(site0[, 1], site0[, 2], sep = &quot;.&quot;)
site1 &lt;- paste(site1[, 1], site1[, 2], sep = &quot;.&quot;)
str(site0)
</code></pre>

<pre><code>##  chr [1:33] &quot;1.5&quot; &quot;1.12&quot; &quot;5.73&quot; &quot;5.80&quot; &quot;5.83&quot; &quot;5.110&quot; ...
</code></pre>

<pre><code class="r">str(site1)
</code></pre>

<pre><code>##  chr [1:18] &quot;1.5&quot; &quot;1.12&quot; &quot;5.80&quot; &quot;5.133&quot; &quot;13.11&quot; &quot;29.5&quot; ...
</code></pre>

<p>Finaly, we want the intersection between the sites present in 1999 and 2012 so that we might choose a monitor that has data in both periods.</p>

<pre><code class="r">both &lt;- intersect(site0, site1)
print(both)
</code></pre>

<pre><code>##  [1] &quot;1.5&quot;     &quot;1.12&quot;    &quot;5.80&quot;    &quot;13.11&quot;   &quot;29.5&quot;    &quot;31.3&quot;    &quot;63.2008&quot;
##  [8] &quot;67.1015&quot; &quot;85.55&quot;   &quot;101.3&quot;
</code></pre>

<p>Here (above) we can see that there are 10 monitors that were operating in both time periods. However, rather than choose one at random, it might best to choose one that had a reasonable amount of data in each year.</p>

<pre><code class="r">## Find how many observations available at each monitor
pm0$county.site &lt;- with(pm0, paste(County.Code, Site.ID, sep = &quot;.&quot;))
pm1$county.site &lt;- with(pm1, paste(County.Code, Site.ID, sep = &quot;.&quot;))
cnt0 &lt;- subset(pm0, State.Code == 36 &amp; county.site %in% both)
cnt1 &lt;- subset(pm1, State.Code == 36 &amp; county.site %in% both)
</code></pre>

<p>Now that we have subsetted the original data frames to only include the data from the monitors that overlap between 1999 and 2012, we can split the data frames and count the number of observations at each monitor to see which ones have the most observations.</p>

<pre><code class="r">sapply(split(cnt0, cnt0$county.site), nrow)  ## 1999
</code></pre>

<pre><code>##    1.12     1.5   101.3   13.11    29.5    31.3    5.80 63.2008 67.1015 
##      61     122     152      61      61     183      61     122     122 
##   85.55 
##       7
</code></pre>

<pre><code class="r">sapply(split(cnt1, cnt1$county.site), nrow)  ## 2012
</code></pre>

<pre><code>##    1.12     1.5   101.3   13.11    29.5    31.3    5.80 63.2008 67.1015 
##      31      64      31      31      33      15      31      30      31 
##   85.55 
##      31
</code></pre>

<p>A number of monitors seem suitable from the output, but we will focus here on County 63 and site ID 2008. </p>

<pre><code class="r">both.county &lt;- 63
both.id &lt;- 2008

## Choose county 63 and side ID 2008
pm1sub &lt;- subset(pm1, State.Code == 36 &amp; County.Code == both.county &amp; Site.ID == 
    both.id)
pm0sub &lt;- subset(pm0, State.Code == 36 &amp; County.Code == both.county &amp; Site.ID == 
    both.id)
</code></pre>

<p>Now we plot the time series data of PM for the monitor in both years.</p>

<pre><code class="r">dates1 &lt;- as.Date(as.character(pm1sub$Date), &quot;%Y%m%d&quot;)
x1sub &lt;- pm1sub$Sample.Value
dates0 &lt;- as.Date(as.character(pm0sub$Date), &quot;%Y%m%d&quot;)
x0sub &lt;- pm0sub$Sample.Value

## Find global range
rng &lt;- range(x0sub, x1sub, na.rm = T)
par(mfrow = c(1, 2), mar = c(4, 5, 2, 1))
plot(dates0, x0sub, pch = 20, ylim = rng, xlab = &quot;&quot;, ylab = expression(PM[2.5] * 
    &quot; (&quot; * mu * g/m^3 * &quot;)&quot;))
abline(h = median(x0sub, na.rm = T))
plot(dates1, x1sub, pch = 20, ylim = rng, xlab = &quot;&quot;, ylab = expression(PM[2.5] * 
    &quot; (&quot; * mu * g/m^3 * &quot;)&quot;))
abline(h = median(x1sub, na.rm = T))
</code></pre>

<p><img src="figure/unnamed-chunk-10.png" alt="plot of chunk unnamed-chunk-10"/> </p>

<p>From the plot above, we can that median levels of PM (horizontal solid line) have decreased a little from 10.45 in 1999 to 8.29 in 2012. However, perhaps more interesting is that the variation (spread) in the PM values in 2012 is much smaller than it was in 1999. This suggest that not only are median levels of PM lower in 2012, but that there are fewer large spikes from day to day. One issue with the data here is that the 1999 data are from July through December while the 2012 data are recorded in January through April. It would have been better if we&#39;d had full-year data for both years as there could be some seasonal confounding going on.</p>

<h3>Changes in state-wide PM levels</h3>

<p>Although ambient air quality standards are set at the federal level in the U.S. and hence affect the entire country, the actual reduction and management of PM is left to the individual states. States that are not &ldquo;in attainment&rdquo; have to develop a plan to reduce PM so that that the are in attainment (eventually). Therefore, it might be useful to examine changes in PM at the state level. This analysis falls somewhere in between looking at the entire country all at once and looking at an individual monitor.</p>

<p>What we do here is calculate the mean of PM for each state in 1999 and 2012.</p>

<pre><code class="r">mn0 &lt;- with(pm0, tapply(Sample.Value, State.Code, mean, na.rm = TRUE))  ## 1999
mn1 &lt;- with(pm1, tapply(Sample.Value, State.Code, mean, na.rm = TRUE))  ## 2012
## Make separate data frames for states / years
d0 &lt;- data.frame(state = names(mn0), mean = mn0)
d1 &lt;- data.frame(state = names(mn1), mean = mn1)
mrg &lt;- merge(d0, d1, by = &quot;state&quot;)
head(mrg)
</code></pre>

<pre><code>##   state mean.x mean.y
## 1     1 19.956 10.126
## 2    10 14.493 11.236
## 3    11 15.787 11.992
## 4    12 11.137  8.240
## 5    13 19.943 11.321
## 6    15  4.862  8.749
</code></pre>

<p>Now make a plot that shows the 1999 state-wide means in one &ldquo;column&rdquo; and the 2012 state-wide means in another columns. We then draw a line connecting the means for each year in the same state to highlight the trend.</p>

<pre><code class="r">par(mfrow = c(1, 1))
rng &lt;- range(mrg[, 2], mrg[, 3])
with(mrg, plot(rep(1, 52), mrg[, 2], xlim = c(0.5, 2.5), ylim = rng, xaxt = &quot;n&quot;, 
    xlab = &quot;&quot;, ylab = &quot;State-wide Mean PM&quot;))
with(mrg, points(rep(2, 52), mrg[, 3]))
segments(rep(1, 52), mrg[, 2], rep(2, 52), mrg[, 3])
axis(1, c(1, 2), c(&quot;1999&quot;, &quot;2012&quot;))
</code></pre>

<p><img src="figure/unnamed-chunk-12.png" alt="plot of chunk unnamed-chunk-12"/> </p>

<p>From the plot above we can see that many states have decreased the average PM levels from 1999 to 2012 (although a few states actually increased their levels). </p>

</body>

</html>

